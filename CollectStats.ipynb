{"cells":[{"cell_type":"markdown","metadata":{"id":"wucZpk7AkVBb"},"source":["# Collect Stats"]},{"cell_type":"markdown","metadata":{"id":"5hz3NDZPkVBe"},"source":["In this notebook, we will apply Neural Fine Gray on the FRAMINGHAM data."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GT8qr1PQNIni","executionInfo":{"status":"ok","timestamp":1746328814288,"user_tz":420,"elapsed":97510,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"252d732f-cb88-479d-b854-4964fd58bf1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"lKCcg2z8rTQa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746328814484,"user_tz":420,"elapsed":198,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"410c9b5f-a767-4874-f8e8-0620e7befce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DLHC\n"]}],"source":["cd /content/drive/MyDrive/DLHC"]},{"cell_type":"code","source":["from getpass import getpass\n","\n","# Enter token securely\n","token = getpass(\"Enter your GitHub token: \")\n","\n","# Set remote URL with token\n","remote_url = f\"https://DrEaston:{token}@github.com/DrEaston/DLHC.git\"\n","\n"],"metadata":{"id":"BTYtwL1M4Qok","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746329664923,"user_tz":420,"elapsed":7975,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"e3f4e5a9-eb47-4471-992d-06228470d0de"},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your GitHub token: ··········\n"]}]},{"cell_type":"code","source":["! git push origin main"],"metadata":{"id":"6_7AsU364mIX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746329666309,"user_tz":420,"elapsed":408,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"c5f7e96a-6f20-4ceb-b75c-2d46a17bc2b6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Everything up-to-date\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u7dGYjBoXCFX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!  git config --global user.email \"curtis.easton@gmail.com\"\n","!  git config --global user.name \"DrEaston\""],"metadata":{"id":"c4m_QtiI7m95","executionInfo":{"status":"ok","timestamp":1746329667445,"user_tz":420,"elapsed":207,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"F1nUmAiODR1n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746329432750,"user_tz":420,"elapsed":23286,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"8cbb656d-95f0-4193-b90b-657de0686bba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-survival\n","  Downloading scikit_survival-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ecos (from scikit-survival)\n","  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.4.2)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.10.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.0.2)\n","Collecting osqp<1.0.0,>=0.6.3 (from scikit-survival)\n","  Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (2.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.15.2)\n","Requirement already satisfied: scikit-learn<1.7,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from scikit-survival) (1.6.1)\n","Collecting qdldl (from osqp<1.0.0,>=0.6.3->scikit-survival)\n","  Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7,>=1.6.1->scikit-survival) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n","Downloading scikit_survival-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.3/298.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: qdldl, ecos, osqp, scikit-survival\n","  Attempting uninstall: osqp\n","    Found existing installation: osqp 1.0.3\n","    Uninstalling osqp-1.0.3:\n","      Successfully uninstalled osqp-1.0.3\n","Successfully installed ecos-2.0.14 osqp-0.6.7.post3 qdldl-0.1.7.post5 scikit-survival-0.24.1\n","Collecting pycox\n","  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\n","Collecting torchtuples>=0.2.0 (from pycox)\n","  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\n","Collecting feather-format>=0.4.0 (from pycox)\n","  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox) (3.13.0)\n","Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox) (0.60.0)\n","Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from pycox) (1.6.1)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pycox) (2.32.3)\n","Collecting py7zr>=0.11.3 (from pycox)\n","  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from feather-format>=0.4.0->pycox) (18.1.0)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py>=2.9.0->pycox) (2.0.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox) (0.43.0)\n","Collecting texttable (from py7zr>=0.11.3->pycox)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting pycryptodomex>=3.16.0 (from py7zr>=0.11.3->pycox)\n","  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr>=0.11.3->pycox)\n","  Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr>=0.11.3->pycox)\n","  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox)\n","  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox)\n","  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox)\n","  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox) (5.9.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pycox) (2025.4.26)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.2->pycox) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.2->pycox) (3.6.0)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from torchtuples>=0.2.0->pycox) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from torchtuples>=0.2.0->pycox) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.17.0)\n","Downloading pycox-0.3.0-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Building wheels for collected packages: feather-format\n","  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=bd2b2d7edb8d35393d49f2a00c7c793352e832d2d98680768156bf2d502ddddc\n","  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n","Successfully built feather-format\n","Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, feather-format, py7zr, torchtuples, pycox\n","Successfully installed brotli-1.1.0 feather-format-0.4.1 inflate64-1.0.1 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.6 pycox-0.3.0 pycryptodomex-3.22.0 pyppmd-1.1.1 pyzstd-0.16.2 texttable-1.7.0 torchtuples-0.2.2\n","Collecting lifelines\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.15.2)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.7.0)\n","Collecting autograd-gamma>=0.3 (from lifelines)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines)\n","  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.13.2)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=5e0d00b05562fc1d137b9a5fc483c861f0a6dbe06a2b08637b736d8370cd970f\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n","Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0\n"]}],"source":["\n","!pip install scikit-survival\n","!pip install pycox\n","!pip install lifelines"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LcVAQ6dGH0Fi","executionInfo":{"status":"ok","timestamp":1746329432753,"user_tz":420,"elapsed":1,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/DLHC')\n","sys.path.append('/content/drive/MyDrive/DLHC/NeuralFineGray')\n","sys.path.append('/content/drive/MyDrive/DLHC/DeepSurvivalMachines')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"BsTHnefWYF1-"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"6f93mJuFHcSu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746329474866,"user_tz":420,"elapsed":42113,"user":{"displayName":"Curtis Easton","userId":"07317615429694306856"}},"outputId":"66c9eb5f-b92a-41bd-e8d5-b03baf57ad6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Opening: FRAMINGHAM_dh.csv  -  dh\n","Opening: FRAMINGHAM_ds.csv  -  ds\n","Opening: FRAMINGHAM_dsm.csv  -  dsm\n","Opening: FRAMINGHAM_nfg.csv  -  nfg\n","Metric                CIS                                               \\\n","                  Overall        2153.75         4589.5        6620.75   \n","Risk Model                                                               \n","1.0  DSM    0.697 (0.033)  0.698 (0.056)  0.672 (0.035)  0.664 (0.021)   \n","     dh     0.683 (0.023)  0.666 (0.049)  0.645 (0.030)  0.651 (0.027)   \n","     ds     0.642 (0.039)  0.651 (0.050)  0.629 (0.056)  0.615 (0.037)   \n","     nfg    0.724 (0.016)  0.723 (0.048)  0.692 (0.028)  0.686 (0.017)   \n","\n","Metric            BRS                                               \n","              Overall        2153.75         4589.5        6620.75  \n","Risk Model                                                          \n","1.0  DSM    nan (nan)  0.026 (0.004)  0.069 (0.003)  0.108 (0.008)  \n","     dh     nan (nan)  0.026 (0.004)  0.068 (0.004)  0.108 (0.007)  \n","     ds     nan (nan)  0.043 (0.006)  0.183 (0.029)  0.371 (0.044)  \n","     nfg    nan (nan)  0.027 (0.004)  0.070 (0.003)  0.112 (0.006)  \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-4594f5514911>:111: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n","  table = table.unstack(level=-1).stack(level=0).unstack(level=-1).loc[:, ['CIS', 'BRS']]\n"]}],"source":["# --- Setup\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","\n","from nfg import datasets\n","from experiment import Experiment\n","from metrics import truncated_concordance_td, auc_td, brier_score as bs\n","\n","from pycox.evaluation import EvalSurv\n","from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc, integrated_brier_score\n","from metrics import truncated_concordance_td, auc_td, brier_score as bs\n","\n","# --- Set your dataset\n","dataset = 'FRAMINGHAM'\n","\n","# --- Set the correct path dynamically\n","path = f'/content/drive/MyDrive/DLHC/Results/{dataset}/'\n","\n","# --- Load your data\n","x, t, e, covariates = datasets.load_dataset(dataset, path='./', competing=True, normalize=False)\n","\n","# --- Set evaluation times\n","horizons = [0.25, 0.5, 0.75]\n","times_eval = np.quantile(t[e > 0], horizons)\n","\n","groups = None  # <-- no groups for PBC\n","\n","\n","### Utils: The evaluatino metrics used\n","def evaluate(survival, e = e, t = t, groups = None, times_eval = []):\n","    folds = survival.iloc[:, -1].values\n","    survival = survival.iloc[:, :-1]\n","    survival.columns = pd.MultiIndex.from_frame(pd.DataFrame(index=survival.columns).reset_index().astype(float))\n","\n","    times = survival.columns.get_level_values(1).unique()\n","    results = {}\n","\n","    # If multiple risk, compute cause specific metrics\n","    for r in survival.columns.get_level_values(0).unique():\n","        for fold in np.arange(5):\n","            res = {}\n","            e_train, t_train = e[folds != fold], t[folds != fold]\n","            e_test,  t_test  = e[folds == fold], t[folds == fold]\n","            g_train, g_test = (None, None) if groups is None else (groups[folds != fold], groups[folds == fold])\n","\n","            survival_train = survival[folds != fold][r]\n","            survival_fold = survival[folds == fold][r]\n","\n","            km = EvalSurv(survival_train.T, t_train, e_train != 0, censor_surv = 'km')\n","            test_eval = EvalSurv(survival_fold.T, t_test, e_test == int(r), censor_surv = km)\n","\n","            res['Overall'] = {\n","                    \"CIS\": test_eval.concordance_td(),\n","                }\n","            try:\n","                res['Overall']['BRS'] = test_eval.integrated_brier_score(times.to_numpy())\n","            except: pass\n","\n","            km = (e_train, t_train)\n","            if len(times_eval) > 0:\n","                for te in times_eval:\n","                    try:\n","                        ci, km = truncated_concordance_td(e_test, t_test, 1 - survival_fold.values, times, te, km = km, competing_risk = int(r))\n","                        res[te] = {\n","                            \"CIS\": ci,\n","                            \"BRS\": bs(e_test, t_test, 1 - survival_fold.values, times, te, km = km, competing_risk = int(r))[0]}\n","                    except:\n","                        pass\n","\n","                    for group in groups.unique() if groups is not None else []:\n","                        try:\n","                            km = (e_train[g_train == group], t_train[g_train == group])\n","                            res[te][\"CIS_{}\".format(group)] = truncated_concordance_td(e_test[g_test == group], t_test[g_test == group], 1 - survival_fold[g_test == group].values, times, te, km = km, competing_risk = int(r))[0]\n","                            res[te][\"BRS_{}\".format(group)] = bs(e_test[g_test == group], t_test[g_test == group], 1 - survival_fold[g_test == group].values, times, te, km = km, competing_risk = int(r))[0]\n","\n","                            km = (e_train[g_train != group], t_train[g_train != group])\n","                            res[te][\"Delta_CIS_{}\".format(group)] = res[te][\"CIS_{}\".format(group)] - truncated_concordance_td(e_test[g_test != group], t_test[g_test != group], 1 - survival_fold[g_test != group].values, times, te, km = km, competing_risk = int(r))[0]\n","                            res[te][\"Delta_BRS_{}\".format(group)] = res[te][\"BRS_{}\".format(group)] - bs(e_test[g_test != group], t_test[g_test != group], 1 - survival_fold[g_test != group].values, times, te, km = km, competing_risk = int(r))[0]\n","\n","                        except:\n","                            pass\n","            results[(r, fold)] = pd.DataFrame.from_dict(res)\n","    results = pd.concat(results)\n","    results.index.set_names(['Risk', 'Fold', 'Metric'], inplace = True)\n","\n","    return results\n","\n","\n"]},{"cell_type":"code","source":["# --- Load predictions and compute metrics\n","predictions, results, models = {}, {}, {}\n","for file_name in os.listdir(path):\n","    if dataset in file_name and (('.csv' in file_name) or ('.csv.gz' in file_name)):\n","        model = file_name\n","        model = model[model.rindex('_') + 1: model.index('.')]\n","        print(\"Opening:\", file_name, ' - ', model)\n","\n","        predictions[model] = pd.read_csv(path + file_name, header=[0, 1], index_col=0)\n","        results[model] = evaluate(predictions[model], groups=groups, times_eval=times_eval)\n","\n","# --- Rename models nicely\n","dict_name = {'dsm': 'DSM'}  # keep simple for now\n","\n","results = pd.concat(results).rename(dict_name)\n","results.index.set_names('Model', level=0, inplace=True)\n","\n","# --- Summarize results\n","table = results.groupby(['Model', 'Risk', 'Metric']).apply(\n","    lambda x: pd.Series([\"{:.3f} ({:.3f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index=x.columns)\n",")\n","table = table.unstack(level=-1).stack(level=0).unstack(level=-1).loc[:, ['CIS', 'BRS']]\n","table = table.reorder_levels(['Risk', 'Model']).sort_index(level=0, sort_remaining=False)\n","\n","# --- Display table\n","print(table)"],"metadata":{"id":"lttSZ-AUWify"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from metrics import evaluate  # assumes your metrics.py is accessible\n","\n","base_path = '/content/drive/MyDrive/DLHC/NeuralFineGray/Results'\n","all_tables = []\n","\n","# Loop through each dataset directory\n","for dataset in os.listdir(base_path):\n","    path = os.path.join(base_path, dataset) + '/'\n","    if not os.path.isdir(path):\n","        continue\n","\n","    print(f\"\\n🔍 Processing dataset: {dataset}\")\n","    predictions, results = {}, {}\n","\n","    # Load all model prediction CSVs for this dataset\n","    for file_name in os.listdir(path):\n","        if dataset in file_name and file_name.endswith('.csv') and '_dh' not in file_name:\n","            model = file_name[file_name.rindex('_') + 1: file_name.index('.')]\n","            print(\"  → Opening:\", file_name, 'as model', model)\n","            df = pd.read_csv(path + file_name, header=[0, 1], index_col=0)\n","            predictions[model] = df\n","            # Call your own evaluate() function\n","            results[model] = evaluate(df, groups='all', times_eval='default')  # modify args if needed\n","\n","    if not results:\n","        print(f\"⚠️ No usable results for {dataset}\")\n","        continue\n","\n","    # Rename models nicely\n","    dict_name = {'dsm': 'DSM', 'rfg': 'RFG', 'nfg': 'NFG', 'deephit': 'DeepHit'}\n","    results = pd.concat(results).rename(dict_name)\n","    results.index.set_names('Model', level=0, inplace=True)\n","\n","    # Summarize results\n","    table = results.groupby(['Model', 'Risk', 'Metric']).apply(\n","        lambda x: pd.Series([\"{:.3f} ({:.3f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index=x.columns)\n","    )\n","    table = table.unstack(level=-1).stack(level=0).unstack(level=-1).loc[:, ['CIS', 'BRS']]\n","    table = table.reorder_levels(['Risk', 'Model']).sort_index(level=0, sort_remaining=False)\n","\n","    # Add dataset label and collect\n","    table['Dataset'] = dataset\n","    all_tables.append(table.reset_index())\n","\n","# Combine all into one big summary table\n","summary_df = pd.concat(all_tables)\n","summary_df.to_csv(os.path.join(base_path, 'summary_all_datasets.csv'), index=False)\n","print(\"✅ Saved summary_all_datasets.csv\")\n"],"metadata":{"id":"vnFdhqVDWzZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! git push origin main"],"metadata":{"id":"TKBp8oExzqiX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! chmod +x .git/hooks/post-commit"],"metadata":{"id":"GEmpWGfDzLU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rm .git/hooks/post-commit"],"metadata":{"id":"TO6MyQkUzUwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls -l .git/hooks/"],"metadata":{"id":"RvlgOCCrzXWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"w-Ht8ugdzd3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! shutil.copy(\"CollectStats.ipynb\", \"CollectStats_backup.ipynb\")"],"metadata":{"id":"crw75ekWzfA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i-cWxfxZ0MH1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Od24abHZ5c_stmy9yOa_JqwtWgoXiEOS","timestamp":1746147207803}]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}